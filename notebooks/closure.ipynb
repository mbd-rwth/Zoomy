{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from library.misc.io import load_fields_from_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_input = \"/home/ingo/Git/SMM/shallow-moments-simulation/openfoam_data/channelflow_coarse/closure_dataset_input.hdf5\"\n",
    "path_data_output = \"/home/ingo/Git/SMM/shallow-moments-simulation/openfoam_data/channelflow_coarse/closure_dataset_output.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test multi sindy\n",
    "Problem: not working with only two snapshots in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path_data_input, \"r\") as f:\n",
    "    n_iterations = len(f.keys())\n",
    "    Q, Qaux, time = load_fields_from_hdf5(path_data_input, 0)\n",
    "    n_elements = Q.shape[0]\n",
    "    n_fields = Q.shape[1]\n",
    "\n",
    "input = np.zeros((n_iterations, n_elements, n_fields))\n",
    "output = np.zeros((n_iterations, n_elements, n_fields))\n",
    "dts = np.zeros((n_iterations, n_elements)) \n",
    "for i in range(n_iterations):\n",
    "    output[i, :, :] = deepcopy(Q)\n",
    "    Q, Qaux, time = load_fields_from_hdf5(path_data_input, i)\n",
    "    input[i, :, :] = deepcopy(Q)\n",
    "    Q, Qaux, dt = load_fields_from_hdf5(path_data_output, i)\n",
    "    dts[i, :] = dt\n",
    "input = input.reshape(n_iterations*n_elements, n_fields)\n",
    "output = output.reshape(n_iterations*n_elements, n_fields)\n",
    "dts = dts.reshape(n_iterations*n_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go to primitive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_fields):\n",
    "    input[:,i] = input[:,i] / input[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of NAN entries in output: 0/17640\n",
      "number of inf entries in output: 0/17640\n",
      "number of non-zero entries in output: 11697/17640\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"number of NAN entries in output: {np.sum(np.isnan(output) > 0)}/{output.shape[0]*output.shape[1]}\")\n",
    "print(f\"number of inf entries in output: {np.sum(np.isinf(output) > 0)}/{output.shape[0]*output.shape[1]}\")\n",
    "print(f\"number of non-zero entries in output: {np.sum(np.abs(output) > 0)}/{output.shape[0]*output.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [Multiple trajectories](https://pysindy.readthedocs.io/en/latest/examples/1_feature_overview/example.html#Single-trajectory,-pass-in-collection-times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHEATING\n",
    "because we need at least 3 time steps (maybe a custom fd model helps?), I assume a linear relation in time anf sample the output as list [IC, IC+0.5*dQ, IC_dQ]. This is clearly an assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "T_data = []\n",
    "for i in range(n_iterations*n_elements):\n",
    "    x_data.append(np.stack((input[i, :], input[i,:] + 0.5 *output[i, :], input[i,:] + 1.0 *output[i, :])))\n",
    "    T_data.append( np.array([0, 0.5*dts[i], 1.0 * dts[i]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.linspace(0, len(x_data)-1, len(x_data), dtype=int)\n",
    "from sklearn.model_selection import train_test_split\n",
    "I_train, I_test = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "x_test = [x_data[i] for i in I_test]\n",
    "T_test = [T_data[i] for i in I_test]\n",
    "x_train = [x_data[i] for i in I_train]\n",
    "T_train = [T_data[i] for i in I_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysindy as ps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(h)' = -54.656 h + 120.625 u + 4.898 v + 71.443 h^2 + -181.292 h u + -6.835 h v + 49.196 u^2 + 2.886 u v + -1.292 v^2\n",
      "(u)' = 83.980 u + -47.337 v + -104.058 h u + 58.571 h v + 20.723 u^2 + -7.915 u v + 5.585 v^2\n",
      "(v)' = -0.339 u + 83.966 v + 0.263 h u + -95.569 h v + 0.212 u^2 + 2.095 u v + -0.850 v^2\n"
     ]
    }
   ],
   "source": [
    "## Create data\n",
    "# model = ps.SINDy()\n",
    "# library_identity = ps.IdentityLibrary()\n",
    "# library_poly = ps.PolynomialLibrary(degree=2, include_bias=False)\n",
    "library_custom = ps.CustomLibrary(\n",
    "    library_functions=[lambda x, y, z: abs(y), lambda x, y, z: abs(z)])\n",
    "# combined_library = library_custom\n",
    "combined_library = library_poly\n",
    "# combined_library = library_custom + library_custom * library_custom\n",
    "feature_names = ['h', 'u', 'v']\n",
    "model = ps.SINDy(feature_library = combined_library, feature_names = feature_names)\n",
    "# model = ps.SINDy(feature_library = library_poly)\n",
    "model.fit(x_train, t=T_train, multiple_trajectories=True, unbias=True)\n",
    "model.print()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(model, x_test, T_test):\n",
    "    error = 0.\n",
    "    n_tests = len(x_test)\n",
    "    for i in range(n_tests):\n",
    "        x0 = x_test[i][0]\n",
    "        y = x_test[i][:]\n",
    "        time = T_test[i][:]\n",
    "        y_sim = model.simulate(x0, time)\n",
    "        error += np.linalg.norm((y-y_sim)[:-1, :])\n",
    "    print(error/n_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0176113168263203\n"
     ]
    }
   ],
   "source": [
    "compute_error(model, x_test, T_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(h)' = 0.000\n",
      "(u)' = 0.777 f0(h,u,v) + 0.777 f1(h,u,v)\n",
      "(v)' = 0.777 f0(h,u,v) + 0.777 f1(h,u,v)\n"
     ]
    }
   ],
   "source": [
    "## Create data\n",
    "n_constraints = 5\n",
    "n_targets = x_train[0].shape[1]\n",
    "n_features = 2\n",
    "n_eqns = 3\n",
    "constraint_rhs = np.zeros(n_constraints)\n",
    "constraint_lhs = np.zeros((n_constraints, n_eqns*n_features))\n",
    "# coefficients of Abs(u) == Abs(v) in u'\n",
    "constraint_lhs[0, n_features + 0] = 1\n",
    "constraint_lhs[0, n_features + 1] = -1\n",
    "# coefficients of Abs(u) == Abs(v) in v'\n",
    "constraint_lhs[1, 2*n_features + 0] = 1\n",
    "constraint_lhs[1, 2*n_features + 1] = -1\n",
    "# coefs for u' and v' are the same\n",
    "constraint_lhs[2, 1*n_features + 0] = 1\n",
    "constraint_lhs[2, 2*n_features + 0] = -1\n",
    "# h' is not affcted from Abs(u)\n",
    "constraint_lhs[3, 0] = 1\n",
    "# h' is not affcted from Abs(v)\n",
    "constraint_lhs[4, 1] = 1\n",
    "\n",
    "opt = ps.ConstrainedSR3(constraint_lhs=constraint_lhs, constraint_rhs=constraint_rhs, threshold=0.5, thresholder='l1')\n",
    "# opt = ps.SR3(threshold=0.5, thresholder='l1')\n",
    "# library_identity = ps.IdentityLibrary()\n",
    "library_poly = ps.PolynomialLibrary(degree=2, include_bias=False)\n",
    "library_custom = ps.CustomLibrary(\n",
    "    library_functions=[lambda x, y, z: abs(y), lambda x, y, z: abs(z)])\n",
    "# combined_library = library_custom\n",
    "combined_library = library_custom\n",
    "# combined_library = library_custom + library_custom * library_custom\n",
    "feature_names = ['h', 'u', 'v']\n",
    "model = ps.SINDy(feature_library = combined_library, feature_names = feature_names, optimizer=opt)\n",
    "# model = ps.SINDy(feature_library = library_poly)\n",
    "\n",
    "\n",
    "model.fit(x_train, t=T, multiple_trajectories=True)\n",
    "model.print()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01239209355980192\n"
     ]
    }
   ],
   "source": [
    "compute_error(model, x_test, T_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "- [ ] check why there are so little non-zeros. Something wrong in callback.h?\n",
    "- [ ] generate mid/high resulition data\n",
    "- [ ] use only newtonian model, not chezy\n",
    "- [ ] use level 0 system.\n",
    "- [ ] Ideally, I do not want to recompute the moment projection of the high fidality data every time. Can I just use the first N-levels of a given one? I think this requires changes in `callback.h` and fit the Q fields to the correct size and PICK THE RIGHT FIELDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
